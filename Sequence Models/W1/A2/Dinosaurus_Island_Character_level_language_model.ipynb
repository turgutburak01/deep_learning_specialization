{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "886671a4-1e4b-49b7-bc30-baf7bad46f33",
   "metadata": {
    "id": "886671a4-1e4b-49b7-bc30-baf7bad46f33",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import *\n",
    "import random\n",
    "import pprint\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b62d69e-4a47-4a3c-9021-0ba0ab77b419",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8b62d69e-4a47-4a3c-9021-0ba0ab77b419",
    "outputId": "176c8161-8952-4e8f-b5e0-9c604480ee3d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 19909 total characters and 27 unique characters in your data.\n"
     ]
    }
   ],
   "source": [
    "data = open('dinos.txt', 'r').read()\n",
    "data = data.lower()\n",
    "chars = list(set(data))\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "print('There are %d total characters and %d unique characters in your data.' % (data_size, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12a10d4d-8962-484a-8f41-800bef7b5ff7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "12a10d4d-8962-484a-8f41-800bef7b5ff7",
    "outputId": "df56e151-9ab0-4031-e7cb-a9d9a352524f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(chars)\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56a29770-ebca-4ffa-8726-c6aafc77c936",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "56a29770-ebca-4ffa-8726-c6aafc77c936",
    "outputId": "0752b068-aeda-46ec-db2e-7bf94c8b2d92",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   0: '\\n',\n",
      "    1: 'a',\n",
      "    2: 'b',\n",
      "    3: 'c',\n",
      "    4: 'd',\n",
      "    5: 'e',\n",
      "    6: 'f',\n",
      "    7: 'g',\n",
      "    8: 'h',\n",
      "    9: 'i',\n",
      "    10: 'j',\n",
      "    11: 'k',\n",
      "    12: 'l',\n",
      "    13: 'm',\n",
      "    14: 'n',\n",
      "    15: 'o',\n",
      "    16: 'p',\n",
      "    17: 'q',\n",
      "    18: 'r',\n",
      "    19: 's',\n",
      "    20: 't',\n",
      "    21: 'u',\n",
      "    22: 'v',\n",
      "    23: 'w',\n",
      "    24: 'x',\n",
      "    25: 'y',\n",
      "    26: 'z'}\n",
      "{   '\\n': 0,\n",
      "    'a': 1,\n",
      "    'b': 2,\n",
      "    'c': 3,\n",
      "    'd': 4,\n",
      "    'e': 5,\n",
      "    'f': 6,\n",
      "    'g': 7,\n",
      "    'h': 8,\n",
      "    'i': 9,\n",
      "    'j': 10,\n",
      "    'k': 11,\n",
      "    'l': 12,\n",
      "    'm': 13,\n",
      "    'n': 14,\n",
      "    'o': 15,\n",
      "    'p': 16,\n",
      "    'q': 17,\n",
      "    'r': 18,\n",
      "    's': 19,\n",
      "    't': 20,\n",
      "    'u': 21,\n",
      "    'v': 22,\n",
      "    'w': 23,\n",
      "    'x': 24,\n",
      "    'y': 25,\n",
      "    'z': 26}\n"
     ]
    }
   ],
   "source": [
    "char_to_ix = {ch:i for i, ch in enumerate(chars)}\n",
    "ix_to_char = {i:ch for i, ch in enumerate(chars)}\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(ix_to_char)\n",
    "pp.pprint(char_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61c49c44-4075-435a-9d6e-4c4a67fb5342",
   "metadata": {
    "id": "61c49c44-4075-435a-9d6e-4c4a67fb5342",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# clipping the gradients in the optimization loop\n",
    "def clip(gradients, maxValue):\n",
    "    gradients = copy.deepcopy(gradients)\n",
    "\n",
    "    dWaa, dWax, dWya, db, dby = gradients['dWaa'], gradients['dWax'], gradients['dWya'], gradients['db'], gradients['dby']\n",
    "\n",
    "    for gradient in [dWax, dWaa, dWya, dWya, db, dby]:\n",
    "        np.clip(gradient, -maxValue, maxValue, out = gradient)\n",
    "\n",
    "    gradients = {'dWaa': dWaa, 'dWax': dWax, 'dWya': dWya, 'db': db, 'dby': dby}\n",
    "\n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c5583f8-17d9-41cd-a1bd-ab45b97d394d",
   "metadata": {
    "id": "7c5583f8-17d9-41cd-a1bd-ab45b97d394d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample(parameters, char_to_ix, seed):\n",
    "    Waa, Wax, Wya, by, b = parameters['Waa'], parameters['Wax'], parameters['Wya'], parameters['by'], parameters['b']\n",
    "    vocab_size = by.shape[0]\n",
    "    n_a = Waa.shape[1]\n",
    "\n",
    "    x = np.zeros([vocab_size,1])\n",
    "    a_prev = np.zeros([n_a,1])\n",
    "\n",
    "    indices = []\n",
    "    idx = -1\n",
    "\n",
    "    counter = 0\n",
    "    newline_character = char_to_ix['\\n']\n",
    "\n",
    "    while (idx != newline_character and counter != 50):\n",
    "\n",
    "        a = np.tanh(np.dot(Wax, x) + np.dot(Waa, a_prev) + b)\n",
    "        z = np.dot(Wya, a) + by\n",
    "        y = softmax(z)\n",
    "\n",
    "        np.random.seed(counter + seed)\n",
    "\n",
    "        idx = np.random.choice(range(len(y)), p = y.ravel())\n",
    "\n",
    "        indices.append(idx)\n",
    "\n",
    "        x = np.zeros([vocab_size,1])\n",
    "        x[idx] = 1\n",
    "\n",
    "        a_prev = a\n",
    "\n",
    "        seed += 1\n",
    "        counter += 1\n",
    "\n",
    "    if counter == 50:\n",
    "        indices.append(char_to_ix['\\n'])\n",
    "\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b037e9d-ea48-4119-bfcd-9338e444f85f",
   "metadata": {
    "id": "7b037e9d-ea48-4119-bfcd-9338e444f85f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def optimize(X, Y, a_prev, parameters, learning_rate = 0.01):\n",
    "    loss, cache = rnn_forward(X, Y, a_prev, parameters)\n",
    "\n",
    "    gradients, a = rnn_backward(X, Y, parameters, cache)\n",
    "\n",
    "    gradients = clip(gradients, 5)\n",
    "\n",
    "    parameters = update_parameters(parameters, gradients, learning_rate)\n",
    "\n",
    "    return loss, gradients, a[len(X) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b36bf2b-556a-42df-be0c-9aaf92f0c1b0",
   "metadata": {
    "id": "3b36bf2b-556a-42df-be0c-9aaf92f0c1b0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model(data_x, ix_to_char, char_to_ix, num_iterations = 35000, n_a = 50, dino_names = 7, vocab_size = 27, verbose = False):\n",
    "\n",
    "    n_x, n_y = vocab_size, vocab_size\n",
    "\n",
    "    parameters = initialize_parameters(n_a, n_x, n_y)\n",
    "\n",
    "    loss = get_initial_loss(vocab_size, dino_names)\n",
    "\n",
    "    examples = [x.strip() for x in data_x]\n",
    "\n",
    "    np.random.seed(0)\n",
    "    np.random.shuffle(examples)\n",
    "\n",
    "    a_prev = np.zeros((n_a, 1))\n",
    "\n",
    "    last_dino_name = \"abc\"\n",
    "\n",
    "    for j in range(num_iterations):\n",
    "        idx = j % len(examples)\n",
    "\n",
    "        single_example = examples[idx]\n",
    "        single_example_chars = [char_to_ix[ch] for ch in single_example]\n",
    "        single_example_ix = idx\n",
    "        X = [None] + single_example_chars\n",
    "\n",
    "        ix_newline = [char_to_ix['\\n']]\n",
    "        Y = X[1:] + ix_newline\n",
    "\n",
    "        curr_loss, gradients, a_prev = optimize(X, Y, a_prev, parameters)\n",
    "\n",
    "        if verbose and j in [0, len(examples) -1, len(examples)]:\n",
    "            print(\"j = \" , j, \"idx = \", idx,)\n",
    "        if verbose and j in [0]:\n",
    "            print(\"single_example =\", single_example)\n",
    "            print(\"single_example_chars\", single_example_chars)\n",
    "            print(\"single_example_ix\", single_example_ix)\n",
    "            print(\" X = \", X, \"\\n\", \"Y =       \", Y, \"\\n\")\n",
    "\n",
    "        loss = smooth(loss, curr_loss)\n",
    "\n",
    "        if j % 2000 == 0:\n",
    "\n",
    "            print('Iteration: %d, Loss: %f' % (j, loss) + '\\n')\n",
    "\n",
    "            seed = 0\n",
    "            for name in range(dino_names):\n",
    "                sampled_indices = sample(parameters, char_to_ix, seed)\n",
    "                last_dino_name = get_sample(sampled_indices, ix_to_char)\n",
    "                print(last_dino_name.replace('\\n', ''))\n",
    "\n",
    "                seed += 1\n",
    "\n",
    "            print('\\n')\n",
    "\n",
    "    return parameters, last_dino_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3ac2237-3a44-4974-a717-3448ca4a37bb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e3ac2237-3a44-4974-a717-3448ca4a37bb",
    "outputId": "7cbe3e57-24d3-4dd1-9316-dad279b70039",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j =  0 idx =  0\n",
      "single_example = turiasaurus\n",
      "single_example_chars [20, 21, 18, 9, 1, 19, 1, 21, 18, 21, 19]\n",
      "single_example_ix 0\n",
      " X =  [None, 20, 21, 18, 9, 1, 19, 1, 21, 18, 21, 19] \n",
      " Y =        [20, 21, 18, 9, 1, 19, 1, 21, 18, 21, 19, 0] \n",
      "\n",
      "Iteration: 0, Loss: 23.087336\n",
      "\n",
      "Nkzxwtdmfqoeyhsqwasjkjvu\n",
      "Kneb\n",
      "Kzxwtdmfqoeyhsqwasjkjvu\n",
      "Neb\n",
      "Zxwtdmfqoeyhsqwasjkjvu\n",
      "Eb\n",
      "Xwtdmfqoeyhsqwasjkjvu\n",
      "\n",
      "\n",
      "j =  1535 idx =  1535\n",
      "j =  1536 idx =  0\n",
      "Iteration: 2000, Loss: 27.884160\n",
      "\n",
      "Liusskeomnolxeros\n",
      "Hmdaairus\n",
      "Hytroligoraurus\n",
      "Lecalosapaus\n",
      "Xusicikoraurus\n",
      "Abalpsamantisaurus\n",
      "Tpraneronxeros\n",
      "\n",
      "\n",
      "Iteration: 4000, Loss: 25.901815\n",
      "\n",
      "Mivrosaurus\n",
      "Inee\n",
      "Ivtroplisaurus\n",
      "Mbaaisaurus\n",
      "Wusichisaurus\n",
      "Cabaselachus\n",
      "Toraperlethosdarenitochusthiamamumamaon\n",
      "\n",
      "\n",
      "Iteration: 6000, Loss: 24.608779\n",
      "\n",
      "Onwusceomosaurus\n",
      "Lieeaerosaurus\n",
      "Lxussaurus\n",
      "Oma\n",
      "Xusteonosaurus\n",
      "Eeahosaurus\n",
      "Toreonosaurus\n",
      "\n",
      "\n",
      "Iteration: 8000, Loss: 24.070350\n",
      "\n",
      "Onxusichepriuon\n",
      "Kilabersaurus\n",
      "Lutrodon\n",
      "Omaaerosaurus\n",
      "Xutrcheps\n",
      "Edaksoje\n",
      "Trodiktonus\n",
      "\n",
      "\n",
      "Iteration: 10000, Loss: 23.844446\n",
      "\n",
      "Onyusaurus\n",
      "Klecalosaurus\n",
      "Lustodon\n",
      "Ola\n",
      "Xusodonia\n",
      "Eeaeosaurus\n",
      "Troceosaurus\n",
      "\n",
      "\n",
      "Iteration: 12000, Loss: 23.291971\n",
      "\n",
      "Onyxosaurus\n",
      "Kica\n",
      "Lustrepiosaurus\n",
      "Olaagrraiansaurus\n",
      "Yuspangosaurus\n",
      "Eealosaurus\n",
      "Trognesaurus\n",
      "\n",
      "\n",
      "Iteration: 14000, Loss: 23.382339\n",
      "\n",
      "Meutromodromurus\n",
      "Inda\n",
      "Iutroinatorsaurus\n",
      "Maca\n",
      "Yusteratoptititan\n",
      "Ca\n",
      "Troclosaurus\n",
      "\n",
      "\n",
      "Iteration: 16000, Loss: 23.230478\n",
      "\n",
      "Meutromg\n",
      "Indaa\n",
      "Iustrephopetetos\n",
      "Macaesia\n",
      "Yuspangmhaurosia\n",
      "Cabatopdaryshagmurhavenstactroopherosaurus\n",
      "Trodon\n",
      "\n",
      "\n",
      "Iteration: 18000, Loss: 22.835346\n",
      "\n",
      "Phytromachurus\n",
      "Melaa\n",
      "Mystrioraphurosechosauroshiura\n",
      "Pegalosaurus\n",
      "Yusochlosaurus\n",
      "Egalosaurus\n",
      "Trolhasaurus\n",
      "\n",
      "\n",
      "Iteration: 20000, Loss: 22.934969\n",
      "\n",
      "Onyxosaurus\n",
      "Logaagosaurus\n",
      "Lwusiangosaurus\n",
      "Ola\n",
      "Yusnangosaurus\n",
      "Fabcosaurus\n",
      "Trrangosaurus\n",
      "\n",
      "\n",
      "Iteration: 22000, Loss: 22.747028\n",
      "\n",
      "Onyxnsaurus\n",
      "Liceaeron\n",
      "Mystodon\n",
      "Ola\n",
      "Yusmameosaurus\n",
      "Eiadosaurus\n",
      "Trognchuatisaurus\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parameters, last_name = model(data.split(\"\\n\"), ix_to_char, char_to_ix, 22001, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979c625c-8479-4c57-8bec-380f9434e1e6",
   "metadata": {
    "id": "979c625c-8479-4c57-8bec-380f9434e1e6"
   },
   "source": [
    "## Writing like Shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ed8b176-69fe-4898-86d5-1e3636cc8144",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ed8b176-69fe-4898-86d5-1e3636cc8144",
    "outputId": "5bd9475b-b1c4-41bd-d7d1-df088805e646",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading text data...\n",
      "Creating training set...\n",
      "number of training examples: 31412\n",
      "Vectorizing training set...\n",
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Input, Masking\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.utils import get_file\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from shakespeare_utils import *\n",
    "import sys\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd9b98b4-7066-45bb-8ddb-996cb30bb1a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fd9b98b4-7066-45bb-8ddb-996cb30bb1a8",
    "outputId": "da011d01-0457-4b6d-f051-10b697c63e36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/246 [==============================] - 89s 337ms/step - loss: 2.5518\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7859dcd3ce50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "model.fit(x, y, batch_size=128, epochs=1, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "-ubj-Q0B28Ty",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ubj-Q0B28Ty",
    "outputId": "d45f12f5-aece-4650-8469-1b3814add1cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write the beginning of your poem, the Shakespeare machine will complete it. Your input is: With love in our souls, we take flight\n",
      "\n",
      "\n",
      "Here is your poem: \n",
      "\n",
      "With love in our souls, we take flight,\n",
      "apon thy fraste wherouse dade bloved o made\n",
      "i crehernd libe for maded gen the to nest.\n",
      "and thing then, meritting fivefed best.\n",
      " \n",
      "she ving spy ents and denllife servers seow,\n",
      "who pen the inn'st difors you dost bes in new,\n",
      "let mag bit wor then hin i possed viion lived,\n",
      "my shall'ing tiding on camer a crir\n",
      "if kermss,\n",
      "that bes as the wealls of ye's hame your, awing (rees.\n",
      "\n",
      " \n",
      "elven thou lift ho hato-y"
     ]
    }
   ],
   "source": [
    "generate_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72qPA9Dp3ZAC",
   "metadata": {
    "id": "72qPA9Dp3ZAC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
